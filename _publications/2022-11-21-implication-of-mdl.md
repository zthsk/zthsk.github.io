---
type: "article"
title: "Implications of Minimum Description Length for Adversarial Attack in NLP"
collection: publications
type: review
permalink: /publication/implications-of-mdl
excerpt: 'This paper is about modeling the behavior of adversarial attack models in NLP as a complex causal mechanism and quantifying it.'
date: "2024-04-16"
venue: 'Entropy'
paperurl: 'https://www.mdpi.com/1099-4300/26/5/354'
authors: "Kshitiz Tiwari , Lu Zhang"
---
<h3> Abstract </h3>
Investigating causality to establish novel criteria for training robust natural language processing (NLP) models is an active research area. However, current methods face various challenges such as the difficulties in identifying keyword lexicons and obtaining data from multiple labeled environments. In this paper, we study the problem of robust NLP from a complementary but different angle: we treat the behavior of an attack model as a complex causal mechanism and quantify its algorithmic information using the minimum description length (MDL) framework. Specifically, we use masked language modeling (MLM) to measure the ‘amount of effort” needed to transform from the original text to the altered text. Based on that, we develop techniques for judging whether a specified set of tokens has been altered by the attack, even in the absence of the original text data.


